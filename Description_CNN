This CNN model is built in the same way as the ResNet 50 model for the classification and labeling of random images.


# File path: "/home/nemolinux/Python/sam2/notebooks/Machine Learning model/Model/ML_model_CNN"



# Modification


-code line[94]
# Define image transformations
transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize(256),  # Resize to a larger size for better feature extraction
    transforms.RandomCrop(224),  # Crop back to 224x224
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(15),
    transforms.ColorJitter(brightness=0.2, contrast=0.2),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # ImageNet normalization
])


----------------------------------------------------------------------------------------------------------------------------------


-code line[121]
# Define a simple CNN model
class EnhancedCNN(torch.nn.Module):
    def __init__(self, num_classes):
        super(EnhancedCNN, self).__init__()
        self.conv1 = torch.nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)
        self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
        self.conv3 = torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)
        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2)
        self.flatten = torch.nn.Flatten()
        self.fc1 = torch.nn.Linear(128 * 28 * 28, 512)  # Increase the number of units
        self.fc2 = torch.nn.Linear(512, num_classes)

    def forward(self, x):
        x = torch.nn.functional.relu(self.conv1(x))
        x = self.pool(x)
        x = torch.nn.functional.relu(self.conv2(x))
        x = self.pool(x)
        x = torch.nn.functional.relu(self.conv3(x))
        x = self.pool(x)
        x = self.flatten(x)
        x = torch.nn.functional.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# Initialize model, loss function, and optimizer
model = EnhancedCNN(num_classes).to(device)
criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.0001, max_lr=0.01, step_size_up=10)

# Training loop
for epoch in range(40):  
    model.train()
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)
        
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
    
    print(f"Epoch {epoch + 1}, Loss: {loss.item()}")


----------------------------------------------------------------------------------------------------------------------------------

# Result:

# The accuracy is very low. Just tried different models..


Final number of classes: 30
Training data size: 128
Testing data size: 33
Using device: cuda
Epoch 1, Loss: 3.239453077316284
Epoch 2, Loss: 2.9862616062164307
Epoch 3, Loss: 2.975964307785034
Epoch 4, Loss: 3.123319625854492
Epoch 5, Loss: 2.8600690364837646
Epoch 6, Loss: 2.7319672107696533
Epoch 7, Loss: 2.6614153385162354
Epoch 8, Loss: 2.754866123199463
Epoch 9, Loss: 2.3399477005004883
Epoch 10, Loss: 2.0900840759277344
Epoch 11, Loss: 2.302529811859131
Epoch 12, Loss: 2.368802070617676
Epoch 13, Loss: 2.273042678833008
Epoch 14, Loss: 2.1383678913116455
Epoch 15, Loss: 2.3767104148864746
Epoch 16, Loss: 2.036494493484497
Epoch 17, Loss: 1.9691517353057861
Epoch 18, Loss: 1.8893404006958008
Epoch 19, Loss: 2.131641149520874
Epoch 20, Loss: 2.2536563873291016
Epoch 21, Loss: 1.9888944625854492
Epoch 22, Loss: 1.8616465330123901
Epoch 23, Loss: 1.816270112991333
Epoch 24, Loss: 1.9603389501571655
Epoch 25, Loss: 1.6552623510360718
Epoch 26, Loss: 1.5411555767059326
Epoch 27, Loss: 1.7387759685516357
Epoch 28, Loss: 1.5893551111221313
Epoch 29, Loss: 2.2345592975616455
Epoch 30, Loss: 1.3602532148361206
Epoch 31, Loss: 1.7141953706741333
Epoch 32, Loss: 1.8520889282226562
Epoch 33, Loss: 1.498643398284912
Epoch 34, Loss: 1.7655240297317505
Epoch 35, Loss: 1.7548408508300781
Epoch 36, Loss: 1.6997655630111694
Epoch 37, Loss: 1.469146966934204
Epoch 38, Loss: 1.6735563278198242
Epoch 39, Loss: 1.5882012844085693
Epoch 40, Loss: 1.3003910779953003
Training Accuracy: 57.81%
Test Accuracy: 36.36%
